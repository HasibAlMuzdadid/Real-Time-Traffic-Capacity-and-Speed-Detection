{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%pip install --force-reinstall lapx==0.5.11 supervision==0.24.0 ultralytics==8.3.12 gdown==5.2.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%pip install -q \"numpy<2\" \"matplotlib<3.9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy, scipy, supervision, ultralytics, gdown, lap\n",
    "\n",
    "print(\"numpy:\", numpy.__version__)\n",
    "print(\"scipy:\", scipy.__version__)\n",
    "print(\"supervision:\", supervision.__version__)\n",
    "print(\"ultralytics:\", ultralytics.__version__)\n",
    "print(\"gdown:\", gdown.__version__)\n",
    "print(\"lapx:\", lap.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 30.109829,
     "end_time": "2025-06-25T17:04:16.114794",
     "exception": false,
     "start_time": "2025-06-25T17:03:46.004965",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import math\n",
    "import warnings\n",
    "import cv2 as cv\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import supervision as sv\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import Video\n",
    "from collections import defaultdict, deque\n",
    "from scipy.signal import savgol_filter\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "on_kaggle = os.getenv(\"KAGGLE_KERNEL_RUN_TYPE\") is not None\n",
    "video_url = \"input.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.015838,
     "end_time": "2025-06-25T17:04:16.185816",
     "exception": false,
     "start_time": "2025-06-25T17:04:16.169978",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Video(video_url, width=960, height=540, embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.018421,
     "end_time": "2025-06-25T17:04:17.047737",
     "exception": false,
     "start_time": "2025-06-25T17:04:17.029316",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Cam2WorldMapper:\n",
    "    def __init__(self):\n",
    "        self.M = None \n",
    "\n",
    "    def __call__(self, image_pts):\n",
    "        return self.map(image_pts)\n",
    "\n",
    "    def find_perspective_transform(self, image_pts, world_pts):\n",
    "        image_pts = np.float32(image_pts).reshape(-1, 1, 2)\n",
    "        world_pts = np.float32(world_pts).reshape(-1, 1, 2)\n",
    "        self.M = cv.getPerspectiveTransform(image_pts, world_pts)\n",
    "        return self.M\n",
    "\n",
    "    def map(self, image_pts):\n",
    "        if self.M is None:\n",
    "            raise ValueError(\"Perspective transformation has not been estimated\")\n",
    "        image_pts = np.float32(image_pts).reshape(-1, 1, 2)\n",
    "        return cv.perspectiveTransform(image_pts, self.M).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.019102,
     "end_time": "2025-06-25T17:04:17.075163",
     "exception": false,
     "start_time": "2025-06-25T17:04:17.056061",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_pts = [(830, 410), (1090, 410), (1920, 850), (0, 850)]\n",
    "# road is roughly 32 meters wide and approx. 50 meters long there\n",
    "world_pts = [(0, 0), (32, 0), (32, 50), (0, 50)] \n",
    "\n",
    "mapper = Cam2WorldMapper()\n",
    "mapper.find_perspective_transform(image_pts, world_pts)\n",
    "print(mapper.M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LocalScaleSpeedometer:\n",
    "    def __init__(self, mapper, fps, unit=3.6, window=5, max_kph=300):\n",
    "        self.mapper = mapper\n",
    "        self.fps = float(fps)\n",
    "        self.unit = float(unit)    # m/s -> km/h multiplier (3.6)\n",
    "        self.window = int(window)  # how many centroids to keep for smoothing (deque)\n",
    "        self.max_kph = float(max_kph)\n",
    "        self.pos_hist = defaultdict(lambda: deque(maxlen=self.window))   # stores image centroids (cx,cy)\n",
    "        self.speed_hist = defaultdict(lambda: deque(maxlen=8))           # recent speed estimates for smoothing\n",
    "\n",
    "    def _local_mpp(self, point):\n",
    "        cx, cy = int(round(point[0])), int(round(point[1]))\n",
    "        img_pts = np.array([[cx, cy], [cx + 1, cy], [cx, cy + 1]], dtype=np.float32)\n",
    "        try:\n",
    "            world_pts = self.mapper.map(img_pts)  \n",
    "        except Exception:\n",
    "            return (1e-6, 1e-6)\n",
    "\n",
    "        w00 = world_pts[0]\n",
    "        wx = world_pts[1]\n",
    "        wy = world_pts[2]\n",
    "        mpp_x = float(np.linalg.norm(wx - w00))\n",
    "        mpp_y = float(np.linalg.norm(wy - w00))\n",
    "        if mpp_x == 0:\n",
    "            mpp_x = 1e-6\n",
    "        if mpp_y == 0:\n",
    "            mpp_y = 1e-6\n",
    "        return (mpp_x, mpp_y)\n",
    "\n",
    "    def update_with_centroid(self, frame_idx:int, track_id:int, centroid:tuple):\n",
    "        tid = int(track_id)\n",
    "        cx, cy = int(round(centroid[0])), int(round(centroid[1]))\n",
    "        self.pos_hist[tid].append((cx, cy))\n",
    "\n",
    "        # need at least two points to compute motion\n",
    "        if len(self.pos_hist[tid]) < 2:\n",
    "            return\n",
    "\n",
    "        (x_prev, y_prev), (x_curr, y_curr) = self.pos_hist[tid][-2], self.pos_hist[tid][-1]\n",
    "        dx_px = float(x_curr - x_prev)\n",
    "        dy_px = float(y_curr - y_prev)\n",
    "\n",
    "        # compute local meters-per-pixel at the midpoint\n",
    "        mid = ((x_prev + x_curr) / 2.0, (y_prev + y_curr) / 2.0)\n",
    "        mpp_x, mpp_y = self._local_mpp(mid)\n",
    "\n",
    "        dx_m = dx_px * mpp_x\n",
    "        dy_m = dy_px * mpp_y\n",
    "        ds_m = math.hypot(dx_m, dy_m)\n",
    "\n",
    "        # meters per second (distance per frame * fps)\n",
    "        m_s = ds_m * self.fps\n",
    "        kph = m_s * self.unit\n",
    "\n",
    "        # clip extreme spikes and fallback to previous if too large\n",
    "        if kph < 0:\n",
    "            kph = 0.0\n",
    "        if kph > self.max_kph:\n",
    "            if self.speed_hist[tid]:\n",
    "                kph = float(self.speed_hist[tid][-1])\n",
    "            else:\n",
    "                kph = float(min(kph, self.max_kph))\n",
    "\n",
    "        # smoothing: push and keep history; median used on get_speed\n",
    "        self.speed_hist[tid].append(kph)\n",
    "\n",
    "    def get_speed(self, track_id:int):\n",
    "        tid = int(track_id)\n",
    "        if not self.speed_hist[tid]:\n",
    "            return 0\n",
    "        arr = np.array(self.speed_hist[tid], dtype=float)\n",
    "        return int(round(float(np.median(arr))))\n",
    "\n",
    "    def reset(self, track_id:int):\n",
    "        tid = int(track_id)\n",
    "        if tid in self.pos_hist:\n",
    "            self.pos_hist[tid].clear()\n",
    "        if tid in self.speed_hist:\n",
    "            self.speed_hist[tid].clear()           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.043097,
     "end_time": "2025-06-25T17:04:17.220158",
     "exception": false,
     "start_time": "2025-06-25T17:04:17.177061",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "colors = (\"#007fff\", \"#0072e6\", \"#0066cc\", \"#0059b3\", \"#004c99\", \"#004080\", \"#003366\", \"#00264d\")\n",
    "color_palette = sv.ColorPalette(list(map(sv.Color.from_hex, colors)))\n",
    "\n",
    "# The supervision VideoInfo provides some metadata about the video\n",
    "video_info = sv.VideoInfo.from_video_path(video_url)\n",
    "fps = video_info.fps\n",
    "\n",
    "# Polygonal zone that masks out detected objects that are outside it\n",
    "poly = np.array([(0, 410), (1920, 410), (1920, 850), (0, 850)])\n",
    "zone = sv.PolygonZone(poly, (sv.Position.TOP_CENTER, sv.Position.BOTTOM_CENTER))\n",
    "\n",
    "bbox_annotator = sv.BoxAnnotator(\n",
    "    color=color_palette,\n",
    "    thickness=2,\n",
    "    color_lookup=sv.ColorLookup.TRACK\n",
    ")\n",
    "trace_annotator = sv.TraceAnnotator(\n",
    "    color=color_palette,\n",
    "    position=sv.Position.CENTER,\n",
    "    thickness=2,\n",
    "    trace_length=fps,\n",
    "    color_lookup=sv.ColorLookup.TRACK\n",
    ")\n",
    "label_annotator = sv.RichLabelAnnotator(\n",
    "    color=color_palette,\n",
    "    border_radius=2,\n",
    "    font_size=16,\n",
    "    color_lookup=sv.ColorLookup.TRACK,\n",
    "    text_padding=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false,
    "papermill": {
     "duration": 200.690696,
     "end_time": "2025-06-25T17:07:37.938404",
     "exception": false,
     "start_time": "2025-06-25T17:04:17.247708",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "yolo = YOLO(\"yolo11m.pt\", task=\"detect\")\n",
    "speedometer = LocalScaleSpeedometer(mapper, fps)\n",
    "\n",
    "# ---------------- parameters ----------------\n",
    "max_reuse_gap = 30             # frames after which reappearing ByteTrack id is considered new\n",
    "min_track_frames_for_speed = 3 # only compute speed after this many frames for a track\n",
    "csv_path = \"vehicle_speeds_unique.csv\"\n",
    "output_video = \"annotated.mp4\"\n",
    "\n",
    "# ---------------- state ----------------\n",
    "last_seen_frame = dict()       # {byte_track_id: last_frame_index_seen}\n",
    "first_seen_frame = dict()      # {byte_track_id: first_frame_index_when_current_instance_started}\n",
    "track_history = defaultdict(list)  # centroids for optional counting\n",
    "seen_unique_labels = set()     # set of unique labels assigned (for summary)\n",
    "\n",
    "unique_id_counter = defaultdict(int)   # e.g., {\"Car\": 5, \"Bus\": 2}\n",
    "tracker_to_unique_label = dict()       # maps current ByteTrack id -> \"Car#5\"\n",
    "\n",
    "class_map = {2: \"Car\", 5: \"Bus\", 7: \"Truck\"}\n",
    "\n",
    "csvfile = open(csv_path, \"w\", newline=\"\")\n",
    "csv_writer = csv.DictWriter(csvfile, fieldnames=[\"frame\", \"tracker_id\", \"class\", \"speed_kmh\", \"cx\", \"cy\"])\n",
    "csv_writer.writeheader()\n",
    "\n",
    "width, height = video_info.resolution_wh  \n",
    "width, height = round(width / 32) * 32, round(height / 32) * 32    # YOLO expects the image size to be a multiple of 32\n",
    "\n",
    "classes = [2, 5, 7]  # Car, Bus, Truck\n",
    "conf = 0.4           # Detetion confidence threshold\n",
    "\n",
    "# ---------------- Vehicle Counting (In / Out / Total) ----------------\n",
    "in_line_y = 700   # line near bottom (entry)\n",
    "out_line_y = 500  # line near top (exit)\n",
    "\n",
    "count_in = 0\n",
    "count_out = 0\n",
    "counted_in_ids = set()\n",
    "counted_out_ids = set()\n",
    "\n",
    "font = cv.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 0.9\n",
    "thickness = 2\n",
    "color_in = sv.Color.from_hex(\"#004080\")   \n",
    "color_out = sv.Color.from_hex(\"#f78923\")  \n",
    "font_color = sv.Color.from_hex(\"#004c99\")\n",
    "color_in_bgr = color_in.as_bgr()     \n",
    "color_out_bgr = color_out.as_bgr()\n",
    "font_color_bgr = font_color.as_bgr()\n",
    "\n",
    "# ---------------- blinking line state ----------------\n",
    "blink_duration = 5  \n",
    "in_blink_frames = 0\n",
    "out_blink_frames = 0\n",
    "\n",
    "\n",
    "# ---------------- main loop ----------------\n",
    "frame_idx = 0\n",
    "with sv.VideoSink(output_video, video_info) as sink:\n",
    "    for frame in sv.get_video_frames_generator(video_url):\n",
    "        frame_idx += 1\n",
    "\n",
    "        result = yolo.track(\n",
    "            frame,\n",
    "            classes=classes,\n",
    "            conf=conf,\n",
    "            imgsz=(height, width),\n",
    "            persist=True,\n",
    "            verbose=False,\n",
    "            tracker=\"bytetrack.yaml\",\n",
    "        )\n",
    "\n",
    "        det = sv.Detections.from_ultralytics(result[0])\n",
    "        det = det[zone.trigger(detections=det)]            # filter by polygon zone\n",
    "\n",
    "        labels = []\n",
    "        trace_ids = det.tracker_id if len(det) > 0 else []\n",
    "\n",
    "        xyxy = np.array(det.xyxy) if det.xyxy is not None else np.zeros((0,4))\n",
    "        class_ids = np.array(det.class_id) if det.class_id is not None else np.zeros((len(trace_ids),), dtype=int)\n",
    "\n",
    "        for i, byte_tid in enumerate(list(trace_ids)):\n",
    "            byte_tid = int(byte_tid)\n",
    "\n",
    "            # bounding box -> centroid\n",
    "            if i >= len(xyxy):\n",
    "                continue\n",
    "            x1, y1, x2, y2 = map(int, xyxy[i])\n",
    "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "\n",
    "            # ----------------- Unique label assignment -----------------\n",
    "            class_id = int(class_ids[i]) if i < len(class_ids) else None\n",
    "            class_name = class_map.get(class_id, \"Vehicle\")\n",
    "\n",
    "            # If this ByteTrack id seen before and short gap -> reuse current mapping\n",
    "            if byte_tid in tracker_to_unique_label:\n",
    "                gap = frame_idx - last_seen_frame.get(byte_tid, frame_idx)\n",
    "                if gap > max_reuse_gap:\n",
    "                    # ByteTrack id reappeared after a long gap -> assign a new global unique label\n",
    "                    unique_id_counter[class_name] += 1\n",
    "                    new_label = f\"{class_name}#{unique_id_counter[class_name]}\"\n",
    "                    tracker_to_unique_label[byte_tid] = new_label\n",
    "                # else: keep existing mapping (it's still the same instance)\n",
    "            else:\n",
    "                # first time we see this ByteTrack id -> assign a new global unique label\n",
    "                unique_id_counter[class_name] += 1\n",
    "                new_label = f\"{class_name}#{unique_id_counter[class_name]}\"\n",
    "                tracker_to_unique_label[byte_tid] = new_label\n",
    "\n",
    "            unique_label = tracker_to_unique_label[byte_tid]\n",
    "            seen_unique_labels.add(unique_label)\n",
    "\n",
    "            # ------------- ID reuse protection for speed history -------------\n",
    "            if byte_tid not in last_seen_frame:\n",
    "                # new first appearance\n",
    "                first_seen_frame[byte_tid] = frame_idx\n",
    "                speedometer.reset(byte_tid)\n",
    "                track_history[byte_tid].clear()\n",
    "            else:\n",
    "                gap = frame_idx - last_seen_frame[byte_tid]\n",
    "                if gap > max_reuse_gap:\n",
    "                    # treat as new instance of same ByteTrack id (we already assigned new unique_label above)\n",
    "                    first_seen_frame[byte_tid] = frame_idx\n",
    "                    speedometer.reset(byte_tid)\n",
    "                    track_history[byte_tid].clear()\n",
    "\n",
    "            last_seen_frame[byte_tid] = frame_idx\n",
    "\n",
    "            # --------- update centroid history used for counting/robustness ----------\n",
    "            track_history[byte_tid].append((cx, cy))\n",
    "            if len(track_history[byte_tid]) > 30:\n",
    "                track_history[byte_tid] = track_history[byte_tid][-30:]\n",
    "\n",
    "            # --------- compute speed after stable tracking ----------\n",
    "            seen_duration = frame_idx - first_seen_frame.get(byte_tid, frame_idx)\n",
    "            if seen_duration >= min_track_frames_for_speed:\n",
    "                # Use centroid-based local-scale speed estimator (LocalScaleSpeedometer)\n",
    "                speedometer.update_with_centroid(frame_idx, byte_tid, (cx, cy))\n",
    "                current_speed = speedometer.get_speed(byte_tid)\n",
    "            else:\n",
    "                current_speed = 0\n",
    "\n",
    "            labels.append(f\"{unique_label} {current_speed} km/h\")\n",
    "\n",
    "            csv_writer.writerow({\n",
    "                \"frame\": frame_idx,\n",
    "                \"tracker_id\": unique_label,\n",
    "                \"class\": class_name,\n",
    "                \"speed_kmh\": current_speed,\n",
    "                \"cx\": cx,\n",
    "                \"cy\": cy\n",
    "            })\n",
    "\n",
    "\n",
    "        # ---------- Vehicle Counting Logic ----------\n",
    "        mid_x = width // 2\n",
    "\n",
    "        for byte_tid in trace_ids:\n",
    "            if byte_tid not in track_history:\n",
    "                continue\n",
    "        \n",
    "            curr_cx, curr_cy = track_history[byte_tid][-1]\n",
    "            prev_cx, prev_cy = track_history[byte_tid][-2] if len(track_history[byte_tid]) >= 2 else (None, None)\n",
    "        \n",
    "            # ---------- IN count (left half, moving UP or first frame) ----------\n",
    "            if byte_tid not in counted_in_ids and curr_cx <= mid_x:\n",
    "                if prev_cy is None:\n",
    "                    # first detection frame, vehicle already above IN line\n",
    "                    if curr_cy <= in_line_y:\n",
    "                        count_in += 1\n",
    "                        counted_in_ids.add(byte_tid)\n",
    "                else:\n",
    "                    # line crossed upward\n",
    "                    if prev_cy > in_line_y >= curr_cy:   \n",
    "                        count_in += 1\n",
    "                        counted_in_ids.add(byte_tid)\n",
    "                        in_blink_frames = blink_duration  \n",
    "\n",
    "            # ---------- OUT count (right half, moving DOWN or already below OUT line at first detection) ----------\n",
    "            if byte_tid not in counted_out_ids and curr_cx > mid_x:\n",
    "                if prev_cy is None:\n",
    "                    # first detection and already below or on OUT line\n",
    "                    if curr_cy >= out_line_y:\n",
    "                        count_out += 1\n",
    "                        counted_out_ids.add(byte_tid)\n",
    "                else:\n",
    "                    # normal downward crossing\n",
    "                    if prev_cy <= out_line_y <= curr_cy:\n",
    "                        count_out += 1\n",
    "                        counted_out_ids.add(byte_tid)\n",
    "                        out_blink_frames = blink_duration  \n",
    "        \n",
    "        # ---------- Annotations / drawing ----------\n",
    "        frame_rgb = cv.cvtColor(cv.cvtColor(frame, cv.COLOR_BGR2GRAY), cv.COLOR_GRAY2RGB)\n",
    "\n",
    "        if len(det) > 0:\n",
    "            frame_rgb = bbox_annotator.annotate(frame_rgb, det)\n",
    "            frame_rgb = trace_annotator.annotate(frame_rgb, det)\n",
    "            if labels:\n",
    "                frame_rgb = label_annotator.annotate(frame_rgb, det, labels=labels)\n",
    "            else:\n",
    "                frame_rgb = label_annotator.annotate(frame_rgb, det)\n",
    "\n",
    "        # IN line blink\n",
    "        overlay = frame_rgb.copy()\n",
    "        if in_blink_frames > 0:\n",
    "            cv.line(overlay, (0, in_line_y), (mid_x-50, in_line_y), (255, 255, 255), 6)\n",
    "            frame_rgb = cv.addWeighted(overlay, 0.7, frame_rgb, 0.3, 0)\n",
    "            in_blink_frames -= 1\n",
    "        else:\n",
    "            cv.line(frame_rgb, (0, in_line_y), (mid_x-50, in_line_y), color_in_bgr, 3)\n",
    "\n",
    "        # OUT line blink\n",
    "        overlay = frame_rgb.copy()\n",
    "        if out_blink_frames > 0:\n",
    "            cv.line(overlay, (mid_x+20, out_line_y), (width, out_line_y), (255, 255, 255), 6)\n",
    "            frame_rgb = cv.addWeighted(overlay, 0.7, frame_rgb, 0.3, 0)\n",
    "            out_blink_frames -= 1\n",
    "        else:\n",
    "            cv.line(frame_rgb, (mid_x+20, out_line_y), (width, out_line_y), color_out_bgr, 3)\n",
    "\n",
    "        # ---------- Draw Counter Overlay ----------\n",
    "        cv.putText(frame_rgb, f\"Vehicles Entered: {count_in}\", (40, 60), font, font_scale, font_color_bgr, thickness)\n",
    "        cv.putText(frame_rgb, f\"Vehicles Left: {count_out}\", (40, 100), font, font_scale, font_color_bgr, thickness)\n",
    "        cv.putText(frame_rgb, f\"Total Vehicles: {len(seen_unique_labels)}\", (40, 140), font, font_scale, font_color_bgr, thickness)\n",
    "\n",
    "        sink.write_frame(frame_rgb)\n",
    "\n",
    "csvfile.close()\n",
    "\n",
    "print(f\"Done â€” unique vehicles assigned: {len(seen_unique_labels)}. CSV saved to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "papermill": {
     "duration": 27.507428,
     "end_time": "2025-06-25T17:08:05.455767",
     "exception": false,
     "start_time": "2025-06-25T17:07:37.948339",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "compressed = \"annotated_compressed.mp4\"\n",
    "subprocess.run(\n",
    "    [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\",\n",
    "        output_video,\n",
    "        \"-crf\",\n",
    "        \"18\",\n",
    "        \"-preset\",\n",
    "        \"veryfast\",\n",
    "        \"-vcodec\",\n",
    "        \"libx264\",\n",
    "        compressed,\n",
    "        \"-loglevel\",\n",
    "        \"quiet\",\n",
    "        \"-y\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "Video(compressed, width=960, height=540)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/kaggle/working/vehicle_speeds_unique.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Clean ---\n",
    "df = df.dropna(subset=[\"speed_kmh\"])\n",
    "df = df[df[\"speed_kmh\"] > 0]\n",
    "df = df.sort_values([\"tracker_id\", \"frame\"]).reset_index(drop=True)\n",
    "\n",
    "fps = fps\n",
    "\n",
    "# --- Safe smoothing function ---\n",
    "def safe_savgol(x, fps):\n",
    "    n = len(x)\n",
    "    if n < 5:\n",
    "        return pd.Series(x, index=x.index)\n",
    "    window = min(fps, n if n % 2 == 1 else n - 1)\n",
    "    if window < 3:\n",
    "        window = 3\n",
    "    smoothed = savgol_filter(x, window_length=window, polyorder=2)\n",
    "    return pd.Series(smoothed, index=x.index)\n",
    "\n",
    "# --- Apply smoothing per vehicle ---\n",
    "smooth_series = df.groupby(\"tracker_id\")[\"speed_kmh\"].apply(lambda x: safe_savgol(x, fps))\n",
    "smooth_series = smooth_series.reset_index(level=0, drop=True)  # drop tracker_id from index\n",
    "df[\"speed_smooth\"] = smooth_series                             # now indices align\n",
    "\n",
    "# --- Pivot to wide layout (frames x vehicles) ---\n",
    "wide_df = df.pivot(index=\"frame\", columns=\"tracker_id\", values=\"speed_smooth\")\n",
    "\n",
    "# --- Clip extreme outliers ---\n",
    "wide_df = wide_df.clip(\n",
    "    lower=float(np.nanpercentile(wide_df, 1)),\n",
    "    upper=float(np.nanpercentile(wide_df, 99))\n",
    ")\n",
    "\n",
    "# --- Plot ---\n",
    "fig, axes = plt.subplots(2, 1, figsize=(20, 10), tight_layout=True)\n",
    "\n",
    "sns.lineplot(data=wide_df, palette=\"viridis\", linewidth=1.25, ax=axes[0])\n",
    "axes[0].set_xlabel(\"Frame\", color=\"#000000\")\n",
    "axes[0].set_ylabel(\"Speed (km/h)\", color=\"#000000\")\n",
    "axes[0].set_ylim(10, 140)\n",
    "axes[0].get_legend().set_visible(False)\n",
    "axes[0].set_title(\"Vehicle Speed Traces (Smoothed)\", color=\"#000000\", loc=\"center\", pad=40)\n",
    "axes[0].tick_params(colors=\"#000000\")\n",
    "\n",
    "sns.kdeplot(wide_df.to_numpy().ravel(), fill=True, color=\"#004080\", linewidth=1, ax=axes[1])\n",
    "axes[1].set_xlabel(\"Speed (km/h)\",color=\"#000000\")\n",
    "axes[1].set_ylabel(\"Density\", color=\"#000000\")\n",
    "axes[1].set_title(\"Speed Distribution Across All Vehicles\", color=\"#000000\", loc=\"center\", pad=20)\n",
    "axes[1].tick_params(colors=\"#000000\")\n",
    "\n",
    "plt.savefig(\"distribution.png\", dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vehicle_stats = df.groupby(\"tracker_id\")[\"speed_smooth\"].agg(\n",
    "    avg_speed=\"mean\",\n",
    "    max_speed=\"max\"\n",
    ").reset_index()\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(20, 10), tight_layout=True)\n",
    "\n",
    "# --- Average Speed ---\n",
    "sns.barplot(data=vehicle_stats, x=\"tracker_id\", y=\"avg_speed\", palette=\"viridis\", ax=axes[0])\n",
    "axes[0].set_title(\"Average Speed per Vehicle\", color=\"#000000\", fontsize=14)\n",
    "axes[0].set_xlabel(\"Vehicle ID\", color=\"#000000\")\n",
    "axes[0].set_ylabel(\"Speed (km/h)\", color=\"#000000\")\n",
    "axes[0].tick_params(colors=\"#000000\", rotation=90)\n",
    "\n",
    "# --- Max Speed ---\n",
    "sns.barplot(data=vehicle_stats, x=\"tracker_id\", y=\"max_speed\", palette=\"viridis\", ax=axes[1])\n",
    "axes[1].set_title(\"Max Speed per Vehicle\", color=\"#000000\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Vehicle ID\", color=\"#000000\")\n",
    "axes[1].set_ylabel(\"Speed (km/h)\", color=\"#000000\")\n",
    "axes[1].tick_params(colors=\"#000000\", rotation=90)\n",
    "\n",
    "plt.savefig(\"speed.png\", dpi=100)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8519158,
     "sourceId": 13422500,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 273.914346,
   "end_time": "2025-06-25T17:08:17.077990",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-25T17:03:43.163644",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
